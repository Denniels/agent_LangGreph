#!/usr/bin/env python3
"""
Test especÃ­fico para verificar el manejo de valores vacÃ­os
========================================================

Verifica que el sistema de seguimiento funciona correctamente
cuando no hay uso registrado (valores en cero).
"""

import os
import sys

# Agregar path del proyecto
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from modules.utils.usage_tracker import UsageTracker
from modules.utils.streamlit_usage_display import display_usage_metrics
import streamlit as st

def test_zero_usage():
    """Test del sistema con uso en cero"""
    print("ğŸ§ª INICIANDO TEST DE VALORES VACÃOS")
    print("=" * 50)
    
    try:
        # 1. Crear tracker nuevo (sin uso)
        print("\n1ï¸âƒ£ Creando tracker sin uso previo")
        tracker = UsageTracker("test_zero_usage.json")
        
        # 2. Obtener informaciÃ³n de modelo sin uso
        print("\n2ï¸âƒ£ Obteniendo informaciÃ³n sin uso")
        model = "llama-3.1-8b-instant"
        usage_info = tracker.get_usage_info(model)
        
        print(f"   ğŸ¤– Modelo: {usage_info.get('model_description', 'N/A')}")
        print(f"   ğŸ”¥ Requests: {usage_info.get('requests_used', 0)}/{usage_info.get('requests_limit', 0)}")
        print(f"   ğŸ¯ Tokens: {usage_info.get('tokens_used', 0)}/{usage_info.get('tokens_limit', 0)}")
        print(f"   ğŸ“Š Porcentaje: {usage_info.get('requests_percentage', 0)}%")
        print(f"   âœ… Estado: {usage_info.get('status', 'unknown')}")
        
        # 3. Verificar que todos los valores son vÃ¡lidos
        print("\n3ï¸âƒ£ Verificando validez de valores")
        
        # Verificar requests
        requests_used = usage_info.get('requests_used', 0) or 0
        requests_limit = usage_info.get('requests_limit', 0) or 0
        requests_percentage = float(usage_info.get('requests_percentage', 0) or 0)
        
        assert isinstance(requests_used, int), f"requests_used debe ser int, es {type(requests_used)}"
        assert isinstance(requests_limit, int), f"requests_limit debe ser int, es {type(requests_limit)}"
        assert isinstance(requests_percentage, float), f"requests_percentage debe ser float, es {type(requests_percentage)}"
        assert 0 <= requests_percentage <= 100, f"requests_percentage debe estar entre 0-100, es {requests_percentage}"
        
        print(f"   âœ… Requests: {requests_used}/{requests_limit} ({requests_percentage}%)")
        
        # Verificar tokens
        tokens_used = usage_info.get('tokens_used', 0) or 0
        tokens_limit = usage_info.get('tokens_limit', 0) or 0
        tokens_percentage = float(usage_info.get('tokens_percentage', 0) or 0)
        
        assert isinstance(tokens_used, int), f"tokens_used debe ser int, es {type(tokens_used)}"
        assert isinstance(tokens_limit, int), f"tokens_limit debe ser int, es {type(tokens_limit)}"
        assert isinstance(tokens_percentage, float), f"tokens_percentage debe ser float, es {type(tokens_percentage)}"
        assert 0 <= tokens_percentage <= 100, f"tokens_percentage debe estar entre 0-100, es {tokens_percentage}"
        
        print(f"   âœ… Tokens: {tokens_used}/{tokens_limit} ({tokens_percentage}%)")
        
        # 4. Test de resumen diario sin uso
        print("\n4ï¸âƒ£ Verificando resumen diario")
        summary = tracker.get_daily_summary()
        
        print(f"   ğŸ“Š Total requests hoy: {summary['total_requests_today']}")
        print(f"   ğŸ¯ Total tokens hoy: {summary['total_tokens_today']}")
        print(f"   ğŸ¤– Modelos usados: {summary['models_used_today']}")
        
        assert summary['total_requests_today'] == 0, "Total requests debe ser 0"
        assert summary['total_tokens_today'] == 0, "Total tokens debe ser 0"
        assert summary['models_used_today'] == 0, "Modelos usados debe ser 0"
        
        # 5. Test de verificaciÃ³n de lÃ­mites
        print("\n5ï¸âƒ£ Verificando verificaciÃ³n de lÃ­mites")
        can_make, message = tracker.check_can_make_request(model)
        
        print(f"   âœ… Puede hacer consulta: {can_make}")
        print(f"   ğŸ’¬ Mensaje: {message}")
        
        assert can_make == True, "Debe poder hacer consultas cuando no hay uso"
        assert "disponibles" in message.lower(), "Mensaje debe mencionar requests disponibles"
        
        print("\nâœ… TODOS LOS TESTS DE VALORES VACÃOS COMPLETADOS")
        
        # Limpiar archivo de test
        import os
        if os.path.exists("test_zero_usage.json"):
            os.remove("test_zero_usage.json")
            print("ğŸ§¹ Archivo de test limpiado")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error en test de valores vacÃ­os: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_safe_formatting():
    """Test de formateo seguro de valores"""
    print("\nğŸ§ª INICIANDO TEST DE FORMATEO SEGURO")
    print("=" * 50)
    
    try:
        # Test de valores que podrÃ­an causar problemas
        test_values = [
            None,
            0,
            0.0,
            "",
            "0",
            100,
            99.5,
            "99.5"
        ]
        
        print("\n1ï¸âƒ£ Probando formateo de diferentes tipos de valores")
        
        for i, value in enumerate(test_values):
            try:
                # Formateo seguro como en el cÃ³digo real
                safe_value = float(value or 0)
                safe_value = max(0, min(100, safe_value))
                
                print(f"   Test {i+1}: {repr(value)} -> {safe_value:.1f}%")
                
                # Verificar que el valor estÃ¡ en rango vÃ¡lido
                assert 0 <= safe_value <= 100, f"Valor fuera de rango: {safe_value}"
                
            except Exception as e:
                print(f"   âŒ Error con valor {repr(value)}: {e}")
                return False
        
        print("\nâœ… TODOS LOS TESTS DE FORMATEO SEGURO COMPLETADOS")
        return True
        
    except Exception as e:
        print(f"âŒ Error en test de formateo: {e}")
        return False

def main():
    """Ejecutar tests de valores vacÃ­os"""
    print("ğŸš€ INICIANDO TESTS DE VALORES VACÃOS Y FORMATEO")
    print("=" * 70)
    
    results = []
    
    # Test 1: Valores vacÃ­os
    result1 = test_zero_usage()
    results.append(("Test Valores VacÃ­os", result1))
    
    # Test 2: Formateo seguro
    result2 = test_safe_formatting()
    results.append(("Test Formateo Seguro", result2))
    
    # Resumen
    print("\n" + "="*70)
    print("ğŸ“‹ RESUMEN DE TESTS")
    print("=" * 30)
    
    total_tests = len(results)
    passed_tests = sum(1 for _, passed in results if passed)
    
    for test_name, passed in results:
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"   {status} {test_name}")
    
    print(f"\nğŸ“Š RESULTADO FINAL: {passed_tests}/{total_tests} tests pasaron")
    
    if passed_tests == total_tests:
        print("ğŸ‰ Â¡TODOS LOS TESTS DE VALORES VACÃOS COMPLETADOS!")
        print("\nğŸ’¡ El sistema maneja correctamente:")
        print("   â€¢ âœ… Valores en cero sin errores")
        print("   â€¢ âœ… Formateo seguro de porcentajes") 
        print("   â€¢ âœ… ValidaciÃ³n de rangos")
        print("   â€¢ âœ… Manejo de valores None/vacÃ­os")
        print("\nğŸš€ Listo para desplegar la correcciÃ³n")
    else:
        print("âš ï¸ Algunos tests fallaron. Revisar implementaciÃ³n.")
    
    return passed_tests == total_tests

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)