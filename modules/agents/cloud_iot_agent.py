"""
Cloud IoT Agent - Versi√≥n para despliegue en Streamlit Cloud con HuggingFace
===========================================================================

Agente IoT optimizado para cloud usando HuggingFace en lugar de Ollama.
"""

import os
import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import streamlit as st

# Imports del proyecto
from modules.agents.groq_integration import GroqIntegration
from modules.tools.jetson_api_connector import JetsonAPIConnector
from modules.tools.direct_jetson_connector import DirectJetsonConnector
from modules.agents.direct_api_agent import create_direct_api_agent
from modules.agents.langgraph_state import IoTAgentState, create_initial_state
from modules.utils.usage_tracker import usage_tracker

# LangGraph imports
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

logger = logging.getLogger(__name__)

# üß† SISTEMAS DE INTELIGENCIA AVANZADA - INTEGRACI√ìN COMPLETA
try:
    from modules.intelligence.smart_analyzer import SmartAnalyzer
    from modules.intelligence.dynamic_sensor_detector import DynamicSensorDetector
    from modules.intelligence.advanced_report_generator import AdvancedReportGenerator
    from modules.intelligence.automatic_insights_engine import AutomaticInsightsEngine
    from modules.intelligence.predictive_analysis_engine import PredictiveAnalysisEngine
    from modules.intelligence.advanced_visualization_engine import AdvancedVisualizationEngine
    from modules.intelligence.intelligent_alert_system import IntelligentAlertSystem
    from modules.intelligence.temporal_comparison_engine import TemporalComparisonEngine
    INTELLIGENCE_SYSTEMS_AVAILABLE = True
    logger.info("üß† SISTEMAS DE INTELIGENCIA AVANZADA CARGADOS EXITOSAMENTE")
except ImportError as e:
    INTELLIGENCE_SYSTEMS_AVAILABLE = False
    logger.error(f"‚ùå Error cargando sistemas de inteligencia: {e}")
except Exception as e:
    INTELLIGENCE_SYSTEMS_AVAILABLE = False
    logger.error(f"‚ùå Error inicializando sistemas de inteligencia: {e}")

# LangGraph imports
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

logger = logging.getLogger(__name__)

# Import del motor de visualizaci√≥n
try:
    from modules.utils.visualization_engine import create_visualization_engine
    VISUALIZATION_AVAILABLE = True
    logger.info("üé® Motor de visualizaci√≥n cargado exitosamente")
except ImportError as e:
    VISUALIZATION_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Motor de visualizaci√≥n no disponible: {e}")

class CloudIoTAgent:
    """
    Agente IoT para cloud que usa Groq en lugar de Ollama/HuggingFace.
    Optimizado para despliegue en Streamlit Cloud.
    """
    
    def __init__(self, 
                 groq_model: str = "llama-3.1-8b-instant",
                 jetson_api_url: str = None):
        """
        Inicializar Cloud IoT Agent.
        
        Args:
            groq_model: Modelo de Groq a usar (gratuito)
            jetson_api_url: URL de la API de Jetson
        """
        self.groq_model = groq_model
        self.jetson_api_url = jetson_api_url or os.getenv(
            "JETSON_API_URL", 
            "https://replica-subscriber-permission-restricted.trycloudflare.com"
        )
        
        # Inicializar componentes
        self.groq_integration = None
        self.jetson_connector = None
        self.direct_api_agent = None  # Fallback robusto
        self.graph = None
        self.memory = MemorySaver()
        
        # Motor de visualizaci√≥n (inicializaci√≥n con fallback)
        self.visualization_engine = None
        try:
            from modules.utils.visualization_engine import IoTVisualizationEngine
            self.visualization_engine = IoTVisualizationEngine()
            logger.info("‚úÖ Motor de visualizaci√≥n inicializado")
        except ImportError as e:
            logger.warning(f"Motor de visualizaci√≥n no disponible: {e}")
        except Exception as e:
            logger.error(f"Error inicializando motor de visualizaci√≥n: {e}")
        
        # üß† INICIALIZAR SISTEMAS DE INTELIGENCIA AVANZADA
        self.intelligence_systems = {}
        if INTELLIGENCE_SYSTEMS_AVAILABLE:
            try:
                self.intelligence_systems = {
                    'smart_analyzer': SmartAnalyzer(),
                    'sensor_detector': DynamicSensorDetector(jetson_api_url=self.jetson_api_url),
                    'report_generator': AdvancedReportGenerator(jetson_api_url=self.jetson_api_url),
                    'insights_engine': AutomaticInsightsEngine(jetson_api_url=self.jetson_api_url),
                    'predictive_engine': PredictiveAnalysisEngine(jetson_api_url=self.jetson_api_url),
                    'visualization_engine': AdvancedVisualizationEngine(jetson_api_url=self.jetson_api_url),
                    'alert_system': IntelligentAlertSystem(jetson_api_url=self.jetson_api_url),
                    'temporal_engine': TemporalComparisonEngine(jetson_api_url=self.jetson_api_url)
                }
                logger.info("üß† SISTEMAS DE INTELIGENCIA AVANZADA INICIALIZADOS")
                logger.info(f"   üìä SmartAnalyzer: ‚úÖ")
                logger.info(f"   üîç DynamicSensorDetector: ‚úÖ")
                logger.info(f"   üìã AdvancedReportGenerator: ‚úÖ")
                logger.info(f"   üí° AutomaticInsightsEngine: ‚úÖ")
                logger.info(f"   üîÆ PredictiveAnalysisEngine: ‚úÖ")
                logger.info(f"   üìà AdvancedVisualizationEngine: ‚úÖ")
                logger.info(f"   üö® IntelligentAlertSystem: ‚úÖ")
                logger.info(f"   ‚è∞ TemporalComparisonEngine: ‚úÖ")
            except Exception as e:
                logger.error(f"‚ùå Error inicializando sistemas de inteligencia: {e}")
                self.intelligence_systems = {}
        else:
            logger.warning("‚ö†Ô∏è Sistemas de inteligencia no disponibles - usando an√°lisis b√°sico")
        
        # Estado del agente
        self.is_initialized = False
        self.last_health_check = None
        
        # Inicializar DirectAPIAgent inmediatamente (fallback robusto)
        try:
            self.direct_api_agent = create_direct_api_agent(self.jetson_api_url)
            logger.info("‚úÖ DirectAPIAgent inicializado como fallback robusto")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è No se pudo inicializar DirectAPIAgent: {e}")
        
        logger.info(f"Cloud IoT Agent creado con modelo: {groq_model}")
    
    async def initialize(self) -> bool:
        """
        Inicializar componentes del agente de forma as√≠ncrona.
        
        Returns:
            True si la inicializaci√≥n fue exitosa
        """
        try:
            logger.info("üöÄ Inicializando Cloud IoT Agent...")
            
            # 1. Inicializar Groq Integration
            groq_api_key = os.getenv("GROQ_API_KEY")
            
            if groq_api_key == "demo_mode" or not groq_api_key or groq_api_key.startswith("demo"):
                # Usar modo demo
                self.groq_integration = GroqIntegration()  # Sin API key = modo fallback
                logger.info("üé≠ Usando Groq en modo DEMO")
            else:
                # Usar Groq real
                self.groq_integration = GroqIntegration(api_key=groq_api_key)
            
            # 2. Inicializar conectores con prioridad
            # PRIORIDAD 1: Conector directo (igual que dashboard exitoso)
            self.direct_connector = DirectJetsonConnector(self.jetson_api_url)
            logger.info("‚úÖ DirectJetsonConnector inicializado")
            
            # PRIORIDAD 2: Conector tradicional (fallback)
            self.jetson_connector = JetsonAPIConnector(base_url=self.jetson_api_url)
            
            # PRIORIDAD 3: Agente directo (√∫ltimo fallback)
            self.direct_api_agent = create_direct_api_agent(self.jetson_api_url)
            
            # 4. Probar conexiones
            groq_test = self.groq_integration.test_connection()
            jetson_test = self.jetson_connector.get_health_status() if self.jetson_connector else {"status": "not_configured"}
            
            if not groq_test.get('success', False):
                logger.warning(f"Groq API no disponible: {groq_test}. Usando modo fallback.")
                # Continuar en modo fallback
            
            if not jetson_test.get('status') == 'healthy':
                logger.warning(f"Jetson API no disponible: {jetson_test}")
                # Continuar sin Jetson (modo demo)
            
            # 5. Construir graph
            self._build_graph()
            
            self.is_initialized = True
            self.last_health_check = datetime.now()
            
            logger.info("‚úÖ Cloud IoT Agent inicializado exitosamente")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando Cloud IoT Agent: {e}")
            # Continuar en modo fallback
            self.groq_integration = GroqIntegration()  # Sin API key
            self._build_graph()
            self.is_initialized = True
            logger.info("‚ö†Ô∏è Cloud IoT Agent inicializado en modo fallback")
            return True
    
    def _build_graph(self):
        """Construir el graph de LangGraph para cloud."""
        
        # Crear StateGraph
        workflow = StateGraph(IoTAgentState)
        
        # Agregar nodos
        workflow.add_node("query_analyzer", self._query_analyzer_node)
        workflow.add_node("remote_data_collector", self._remote_data_collector_node)
        workflow.add_node("data_analyzer", self._data_analyzer_node)
        workflow.add_node("response_generator", self._response_generator_node)
        workflow.add_node("data_verification", self._data_verification_node)
        
        # Configurar flujo
        workflow.set_entry_point("query_analyzer")
        
        # Edges del flujo
        workflow.add_edge("query_analyzer", "remote_data_collector")
        workflow.add_edge("remote_data_collector", "data_analyzer")
        workflow.add_edge("data_analyzer", "response_generator")
        workflow.add_edge("response_generator", "data_verification")
        workflow.add_edge("data_verification", END)
        
        # Compilar graph
        self.graph = workflow.compile(checkpointer=self.memory)
        
        logger.info("üìä Graph de LangGraph construido para cloud")
    
    async def _query_analyzer_node(self, state: IoTAgentState) -> IoTAgentState:
        """
        Nodo para analizar la consulta del usuario.
        
        Args:
            state: Estado actual del agente
            
        Returns:
            Estado actualizado
        """
        try:
            logger.info("üîç Ejecutando query_analyzer_node (Cloud)")
            
            user_query = state["user_query"]
            
            # An√°lisis simple de la consulta
            analysis = {
                "intent": "sensor_data_query",
                "requires_data": True,
                "sensors_mentioned": [],
                "devices_mentioned": [],
                "timestamp": datetime.now().isoformat()
            }
            
            # Detectar sensores mencionados
            sensor_keywords = ["temperatura", "temperature", "sensor", "calor", "grados"]
            if any(keyword in user_query.lower() for keyword in sensor_keywords):
                analysis["sensors_mentioned"] = ["temperature"]
            
            # Detectar dispositivos mencionados
            device_keywords = ["arduino", "esp32", "dispositivo", "device"]
            for keyword in device_keywords:
                if keyword in user_query.lower():
                    analysis["devices_mentioned"].append(keyword)
            
            # Actualizar estado
            state["query_analysis"] = analysis
            state["execution_status"] = "query_analyzed"
            
            logger.info(f"   ‚úÖ Consulta analizada: {analysis['intent']}")
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error en query_analyzer_node: {e}")
            state["execution_status"] = "error"
            state["error_details"] = str(e)
            return state
    
    async def _remote_data_collector_node(self, state: IoTAgentState) -> IoTAgentState:
        """
        Nodo ROBUSTO para recolectar datos con fallback directo que S√ç FUNCIONA.
        
        ESTRATEGIA:
        1. Intentar conexi√≥n normal del agente
        2. Si falla, usar DirectAPIAgent (misma l√≥gica del frontend exitoso)
        3. Garantizar que el agente tenga acceso a los mismos datos que el frontend
        
        Args:
            state: Estado actual del agente
            
        Returns:
            Estado actualizado
        """
        try:
            logger.info("üì° Ejecutando remote_data_collector_node (ULTRA-ROBUSTO)")
            
            all_data = []
            method_used = "none"
            
            # M√âTODO 1: Conector DIRECTO (igual que dashboard exitoso)
            if self.direct_connector:
                try:
                    logger.info("üöÄ Intentando m√©todo DIRECTO (igual que dashboard)...")
                    
                    # Usar el m√©todo completo que replica el dashboard
                    result = self.direct_connector.get_all_data_simple()
                    
                    if result["status"] == "success" and result["sensor_data"]:
                        all_data = result["sensor_data"]
                        method_used = "direct"
                        logger.info(f"‚úÖ M√©todo DIRECTO exitoso: {len(all_data)} registros")
                        logger.info(f"üìä Stats: {result['stats']}")
                        
                        # Guardar informaci√≥n detallada
                        state["connection_info"] = result["connection"]
                        state["device_info"] = result["devices"]
                        state["data_stats"] = result["stats"]
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è M√©todo DIRECTO fall√≥: {e}")
            
            # M√âTODO 2: M√©todo tradicional (solo si el directo falla)
            if not all_data and self.jetson_connector:
                try:
                    logger.info("üîÑ Intentando m√©todo tradicional...")
                    devices_result = self.jetson_connector.get_devices()
                    
                    if devices_result and not any(d.get("status") == "unknown" for d in devices_result):
                        for device in devices_result:
                            device_id = device.get("device_id")
                            if device_id:
                                device_data = self.jetson_connector.get_sensor_data(
                                    device_id=device_id,
                                    limit=500
                                )
                                if device_data:
                                    all_data.extend(device_data)
                        
                        if all_data:
                            method_used = "traditional"
                            logger.info(f"‚úÖ M√©todo tradicional exitoso: {len(all_data)} registros")
                        else:
                            raise Exception("M√©todo normal no devolvi√≥ datos")
                    else:
                        raise Exception("M√©todo normal no encontr√≥ dispositivos")
                        
                except Exception as normal_error:
                    logger.warning(f"‚ö†Ô∏è M√©todo normal fall√≥: {normal_error}")
                    all_data = []  # Limpiar para intentar fallback
            
            # M√âTODO 2: FALLBACK DIRECTO (usa la misma l√≥gica exitosa del frontend)
            if not all_data:
                try:
                    logger.info("ÔøΩ Activando FALLBACK DIRECTO (frontend logic)...")
                    
                    if hasattr(self, 'direct_api_agent') and self.direct_api_agent:
                        # Usar el agente directo que copia la l√≥gica del frontend
                        # Intentar obtener configuraci√≥n temporal del contexto
                        analysis_hours = 3.0  # Default
                        
                        # Buscar si hay configuraci√≥n temporal en la consulta
                        user_query = state.get("user_query", "")
                        if "CONFIGURACI√ìN TEMPORAL" in user_query:
                            try:
                                import re
                                match = re.search(r"(\d+(?:\.\d+)?)\s*horas", user_query)
                                if match:
                                    analysis_hours = float(match.group(1))
                                    logger.info(f"üìÖ Usando configuraci√≥n temporal: {analysis_hours} horas")
                            except:
                                pass
                        
                        direct_result = self.direct_api_agent.get_all_recent_data(hours=analysis_hours)
                        
                        if direct_result.get("status") == "success":
                            all_data = direct_result.get("sensor_data", [])
                            method_used = "direct_fallback"
                            logger.info(f"‚úÖ FALLBACK DIRECTO exitoso: {len(all_data)} registros")
                        else:
                            logger.error(f"‚ùå Fallback directo fall√≥: {direct_result.get('message', 'Error desconocido')}")
                    else:
                        logger.error("‚ùå Direct API Agent no disponible")
                        
                except Exception as fallback_error:
                    logger.error(f"‚ùå Fallback directo fall√≥: {fallback_error}")
            
            # RESULTADO FINAL
            if all_data:
                state["raw_data"] = all_data
                state["execution_status"] = "remote_data_collected"
                state["data_collection_method"] = method_used
                logger.info(f"üéâ DATOS OBTENIDOS ({method_used}): {len(all_data)} registros")
            else:
                # Si ambos m√©todos fallan, reportar problema
                jetson_status = self._check_jetson_api_status()
                state["raw_data"] = []
                state["execution_status"] = "all_methods_failed"
                state["error"] = {
                    "message": "Tanto m√©todo normal como fallback directo fallaron",
                    "jetson_status": jetson_status,
                    "methods_tried": ["normal", "direct_fallback"]
                }
                logger.error("‚ùå TODOS LOS M√âTODOS FALLARON - No se pudieron obtener datos")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico en remote_data_collector_node: {e}")
            state["raw_data"] = []
            state["execution_status"] = "critical_error"
            state["error"] = {"message": str(e), "type": "critical_error"}
            return state
    
    async def _data_analyzer_node(self, state: IoTAgentState) -> IoTAgentState:
        """
        üß† NODO DE AN√ÅLISIS INTELIGENTE - POTENCIADO POR IA Y ML
        
        Usa todos los sistemas de inteligencia avanzada implementados:
        - SmartAnalyzer: An√°lisis estad√≠stico y detecci√≥n de anomal√≠as
        - DynamicSensorDetector: Detecci√≥n autom√°tica de dispositivos
        - AutomaticInsightsEngine: Generaci√≥n de insights con IA
        - PredictiveAnalysisEngine: Predicciones y an√°lisis temporal
        - IntelligentAlertSystem: Alertas contextuales inteligentes
        
        Args:
            state: Estado actual del agente
            
        Returns:
            Estado actualizado con an√°lisis inteligente completo
        """
        try:
            logger.info("üß† Ejecutando AN√ÅLISIS INTELIGENTE AVANZADO")
            
            raw_data = state.get("raw_data", [])
            user_query = state.get("user_query", "")
            
            # Verificar si hay datos disponibles
            if not raw_data:
                logger.warning("üö® No hay datos para analizar")
                
                # Usar el sistema inteligente de alertas para generar mensaje de error contextual
                if self.intelligence_systems.get('alert_system'):
                    try:
                        error_analysis = self.intelligence_systems['alert_system'].generate_connection_diagnostic()
                        state["formatted_data"] = error_analysis
                    except:
                        state["formatted_data"] = self._generate_fallback_error_message(state)
                else:
                    state["formatted_data"] = self._generate_fallback_error_message(state)
                
                state["sensor_summary"] = {}
                state["analysis"] = {"error": "no_data_available"}
                return state
            
            # üß† AN√ÅLISIS INTELIGENTE AVANZADO CON SISTEMAS DE IA
            logger.info("üîç Iniciando validaci√≥n y sanitizaci√≥n inteligente de datos...")
            
            # PASO 1: SANITIZACI√ìN INTELIGENTE CON SMARTANALYZER
            processed_data = []
            if self.intelligence_systems.get('smart_analyzer'):
                try:
                    # Usar SmartAnalyzer para validaci√≥n y limpieza avanzada
                    processed_data = self.intelligence_systems['smart_analyzer'].validate_and_clean_data(raw_data)
                    logger.info(f"üß† SmartAnalyzer proces√≥: {len(processed_data)}/{len(raw_data)} registros v√°lidos")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è SmartAnalyzer fall√≥, usando sanitizaci√≥n b√°sica: {e}")
                    processed_data = self._basic_data_sanitization(raw_data)
            else:
                processed_data = self._basic_data_sanitization(raw_data)
            
            # Si no hay datos v√°lidos despu√©s de la sanitizaci√≥n
            if not processed_data:
                logger.warning("üö® No hay datos v√°lidos despu√©s de la sanitizaci√≥n")
                if self.intelligence_systems.get('alert_system'):
                    try:
                        error_analysis = self.intelligence_systems['alert_system'].analyze_data_format_error(raw_data[:3])
                        state["formatted_data"] = error_analysis
                    except:
                        state["formatted_data"] = self._generate_data_format_error(raw_data)
                else:
                    state["formatted_data"] = self._generate_data_format_error(raw_data)
                
                state["sensor_summary"] = {}
                state["analysis"] = {"error": "invalid_data_format"}
                return state
            
            # PASO 2: AN√ÅLISIS INTELIGENTE DE CONSULTA CON NLP
            logger.info("üîç Analizando tipo de consulta con sistemas inteligentes...")
            query_analysis = {}
            
            if self.intelligence_systems.get('insights_engine'):
                try:
                    # Usar AutomaticInsightsEngine para analizar la consulta
                    query_analysis = self.intelligence_systems['insights_engine'].analyze_user_query(user_query)
                    logger.info(f"üß† AutomaticInsightsEngine analiz√≥ la consulta: {query_analysis.get('intent', 'unknown')}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è AutomaticInsightsEngine fall√≥, usando an√°lisis b√°sico: {e}")
                    query_analysis = self._basic_query_analysis(user_query)
            else:
                query_analysis = self._basic_query_analysis(user_query)
            
            # PASO 3: DETECCI√ìN DIN√ÅMICA DE SENSORES Y DISPOSITIVOS
            logger.info("üîç Detectando dispositivos y sensores din√°micamente...")
            device_analysis = {}
            
            if self.intelligence_systems.get('sensor_detector'):
                try:
                    # Usar DynamicSensorDetector para an√°lisis autom√°tico
                    device_analysis = self.intelligence_systems['sensor_detector'].analyze_devices_and_sensors(processed_data)
                    logger.info(f"üß† DynamicSensorDetector encontr√≥: {device_analysis.get('total_devices', 0)} dispositivos, {device_analysis.get('total_sensors', 0)} tipos de sensores")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è DynamicSensorDetector fall√≥, usando detecci√≥n b√°sica: {e}")
                    device_analysis = self._basic_device_analysis(processed_data)
            else:
                device_analysis = self._basic_device_analysis(processed_data)
            
            # PASO 4: AN√ÅLISIS ESTAD√çSTICO AVANZADO CON ML
            logger.info("üìä Ejecutando an√°lisis estad√≠stico avanzado...")
            statistical_analysis = {}
            
            if self.intelligence_systems.get('smart_analyzer'):
                try:
                    # Usar SmartAnalyzer para an√°lisis estad√≠stico completo
                    statistical_analysis = self.intelligence_systems['smart_analyzer'].perform_comprehensive_analysis(
                        processed_data, query_analysis, device_analysis
                    )
                    logger.info(f"üß† SmartAnalyzer complet√≥ an√°lisis estad√≠stico: {len(statistical_analysis.get('insights', []))} insights generados")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è SmartAnalyzer fall√≥ en an√°lisis estad√≠stico: {e}")
                    statistical_analysis = self._basic_statistical_analysis(processed_data)
            else:
                statistical_analysis = self._basic_statistical_analysis(processed_data)
            
            # PASO 5: AN√ÅLISIS PREDICTIVO Y TEMPORAL
            logger.info("ÔøΩ Ejecutando an√°lisis predictivo...")
            predictive_analysis = {}
            temporal_analysis = {}
            
            if self.intelligence_systems.get('predictive_engine'):
                try:
                    predictive_analysis = self.intelligence_systems['predictive_engine'].generate_predictions(processed_data)
                    logger.info(f"üß† PredictiveAnalysisEngine gener√≥ predicciones para {len(predictive_analysis.get('predictions', []))} variables")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è PredictiveAnalysisEngine fall√≥: {e}")
            
            if self.intelligence_systems.get('temporal_engine'):
                try:
                    temporal_analysis = self.intelligence_systems['temporal_engine'].analyze_temporal_patterns(processed_data)
                    logger.info(f"üß† TemporalComparisonEngine analiz√≥ patrones temporales")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è TemporalComparisonEngine fall√≥: {e}")
            
            # PASO 6: GENERACI√ìN DE ALERTAS INTELIGENTES
            logger.info("ÔøΩ Generando alertas inteligentes...")
            intelligent_alerts = []
            
            if self.intelligence_systems.get('alert_system'):
                try:
                    intelligent_alerts = self.intelligence_systems['alert_system'].generate_contextual_alerts(
                        processed_data, statistical_analysis, predictive_analysis
                    )
                    logger.info(f"üß† IntelligentAlertSystem gener√≥ {len(intelligent_alerts)} alertas contextuales")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è IntelligentAlertSystem fall√≥: {e}")
            
            # PASO 7: CONSOLIDAR AN√ÅLISIS COMPLETO
            comprehensive_analysis = {
                "query_analysis": query_analysis,
                "device_analysis": device_analysis,
                "statistical_analysis": statistical_analysis,
                "predictive_analysis": predictive_analysis,
                "temporal_analysis": temporal_analysis,
                "intelligent_alerts": intelligent_alerts,
                "total_records": len(processed_data),
                "raw_data_count": len(raw_data),
                "processing_success_rate": (len(processed_data) / len(raw_data)) * 100 if raw_data else 0
            }
            
            # PASO 8: FORMATEO INTELIGENTE DE DATOS
            logger.info("üìã Formateando datos con sistemas inteligentes...")
            formatted_data = ""
            
            if self.intelligence_systems.get('report_generator'):
                try:
                    # Usar AdvancedReportGenerator para formateo inteligente
                    formatted_data = self.intelligence_systems['report_generator'].generate_intelligent_report(
                        processed_data, comprehensive_analysis, user_query
                    )
                    logger.info("üß† AdvancedReportGenerator gener√≥ reporte inteligente")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è AdvancedReportGenerator fall√≥, usando formateo b√°sico: {e}")
                    formatted_data = self._basic_data_formatting(processed_data, comprehensive_analysis)
            else:
                formatted_data = self._basic_data_formatting(processed_data, comprehensive_analysis)
            
            # Actualizar estado con an√°lisis completo
            state["formatted_data"] = formatted_data
            state["sensor_summary"] = device_analysis  # Para compatibilidad
            state["comprehensive_analysis"] = comprehensive_analysis
            state["execution_status"] = "intelligent_analysis_completed"
            
            logger.info(f"‚úÖ AN√ÅLISIS INTELIGENTE COMPLETADO: {len(processed_data)} registros analizados con {len(comprehensive_analysis.get('intelligent_alerts', []))} alertas y {len(statistical_analysis.get('insights', []))} insights")
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error en data_analyzer_node: {e}")
            state["execution_status"] = "error"
            state["error_details"] = str(e)
            return state
    
    async def _response_generator_node(self, state: IoTAgentState) -> IoTAgentState:
        """
        üß† NODO GENERADOR DE RESPUESTAS INTELIGENTES
        
        Utiliza AdvancedReportGenerator y AutomaticInsightsEngine para generar 
        respuestas sofisticadas con IA en lugar de respuestas b√°sicas.
        
        Args:
            state: Estado actual del agente
            
        Returns:
            Estado actualizado con respuesta inteligente
        """
        try:
            logger.info("ÔøΩ Ejecutando GENERACI√ìN DE RESPUESTA INTELIGENTE")
            
            # 1. Verificar l√≠mites de uso antes de hacer la consulta
            can_make_request, usage_message = usage_tracker.check_can_make_request(self.groq_model)
            
            if not can_make_request:
                logger.warning(f"‚ö†Ô∏è L√≠mite de uso alcanzado: {usage_message}")
                state["final_response"] = f"""
üö® **L√çMITE DE USO DIARIO ALCANZADO**

{usage_message}

üìä **Informaci√≥n del l√≠mite**:
- Los l√≠mites se resetean autom√°ticamente cada d√≠a
- Modelo actual: {self.groq_model}

üîÑ **Alternativas**:
- Esperar al reseteo diario (medianoche UTC)
- Continuar ma√±ana cuando se renueven los l√≠mites
- Contactar al administrador si necesitas m√°s consultas

üí° **Informaci√≥n**: Este sistema de control nos ayuda a mantener el servicio gratuito y disponible para todos los usuarios.
"""
                state["execution_status"] = "usage_limit_reached"
                state["usage_info"] = usage_tracker.get_usage_info(self.groq_model)
                return state
            
            # Mostrar informaci√≥n de uso actual si hay advertencia
            if "warning" in usage_message.lower() or "cr√≠tico" in usage_message.lower():
                logger.info(f"üìä {usage_message}")
            
            user_query = state["user_query"]
            formatted_data = state.get("formatted_data", "")
            comprehensive_analysis = state.get("comprehensive_analysis", {})
            
            # üß† GENERAR RESPUESTA INTELIGENTE CON SISTEMAS AVANZADOS
            logger.info("üß† Generando respuesta inteligente con AdvancedReportGenerator...")
            
            intelligent_response = ""
            
            if self.intelligence_systems.get('report_generator') and comprehensive_analysis:
                try:
                    # Usar AdvancedReportGenerator para generar respuesta completa
                    intelligent_response = self.intelligence_systems['report_generator'].generate_intelligent_response(
                        user_query=user_query,
                        analysis_data=comprehensive_analysis,
                        formatted_data=formatted_data
                    )
                    logger.info("üß† AdvancedReportGenerator gener√≥ respuesta inteligente")
                    
                    # Si hay alertas inteligentes, agregarlas a la respuesta
                    if comprehensive_analysis.get('intelligent_alerts'):
                        alert_section = "\n\nüö® ALERTAS INTELIGENTES:\n"
                        for alert in comprehensive_analysis['intelligent_alerts']:
                            alert_section += f"‚Ä¢ {alert}\n"
                        intelligent_response += alert_section
                    
                    # Si hay predicciones, agregarlas
                    if comprehensive_analysis.get('predictive_analysis', {}).get('predictions'):
                        prediction_section = "\n\nüîÆ PREDICCIONES:\n"
                        for prediction in comprehensive_analysis['predictive_analysis']['predictions']:
                            prediction_section += f"‚Ä¢ {prediction}\n"
                        intelligent_response += prediction_section
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è AdvancedReportGenerator fall√≥, usando generaci√≥n b√°sica: {e}")
                    intelligent_response = None
            
            # Si los sistemas inteligentes no generaron respuesta, usar generaci√≥n b√°sica mejorada
            if not intelligent_response:
                logger.info("üîÑ Usando generaci√≥n de respuesta b√°sica mejorada...")
                intelligent_response = self._generate_basic_intelligent_response(
                    user_query, formatted_data, comprehensive_analysis
                )
            
            # 2. GENERAR VISUALIZACIONES INTELIGENTES SI ES NECESARIO
            chart_paths = []
            visualization_info = ""
            
            if self.intelligence_systems.get('visualization_engine'):
                try:
                    # Usar AdvancedVisualizationEngine para generar gr√°ficos inteligentes
                    raw_data = state.get("raw_data", [])
                    if raw_data:
                        chart_result = self.intelligence_systems['visualization_engine'].generate_intelligent_visualizations(
                            raw_data, user_query, comprehensive_analysis
                        )
                        if chart_result.get('charts'):
                            chart_paths = chart_result['charts']
                            visualization_info = chart_result.get('description', '')
                            logger.info(f"üß† AdvancedVisualizationEngine gener√≥ {len(chart_paths)} visualizaciones")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è AdvancedVisualizationEngine fall√≥: {e}")
                    # Fallback al motor de visualizaci√≥n b√°sico
                    if self.visualization_engine:
                        try:
                            should_generate = self.visualization_engine.should_generate_charts(user_query)
                            if should_generate:
                                raw_data = state.get("raw_data", [])
                                if raw_data:
                                    chart_base64_list = self.visualization_engine.generate_charts(raw_data, user_query)
                                    if chart_base64_list:
                                        chart_paths = chart_base64_list
                                        visualization_info = f"Generados {len(chart_base64_list)} gr√°ficos"
                        except Exception as e2:
                            logger.warning(f"‚ö†Ô∏è Motor de visualizaci√≥n b√°sico tambi√©n fall√≥: {e2}")
            
            # 3. GENERAR RESPUESTA FINAL CON GROQ + IA MEJORADA
            if intelligent_response:
                # Usar la respuesta inteligente como base y mejorarla con Groq
                try:
                    # Crear prompt mejorado para Groq usando la respuesta inteligente
                    enhanced_prompt = f"""
Tienes acceso a un an√°lisis inteligente avanzado de datos IoT. Tu trabajo es tomar este an√°lisis 
y crear una respuesta conversacional natural y √∫til para el usuario.

CONSULTA ORIGINAL DEL USUARIO: {user_query}

AN√ÅLISIS INTELIGENTE DISPONIBLE:
{intelligent_response}

CONTEXTO ADICIONAL:
- Total de dispositivos activos: {comprehensive_analysis.get('device_analysis', {}).get('total_devices', 0)}
- Total de sensores: {comprehensive_analysis.get('device_analysis', {}).get('total_sensors', 0)}
- Registros analizados: {comprehensive_analysis.get('total_records', 0)}
{f"- Visualizaciones generadas: {visualization_info}" if visualization_info else ""}

Tu respuesta debe:
1. Ser conversacional y √∫til
2. Incluir insights espec√≠ficos del an√°lisis inteligente
3. Responder directamente la pregunta del usuario
4. Mostrar que entiendes los datos en profundidad
5. Incluir conclusiones y recomendaciones cuando sea apropiado

RESPUESTA CONVERSACIONAL:
"""
                    
                    # Generar respuesta mejorada con Groq
                    groq_response = self.groq_integration.generate_response(enhanced_prompt, model=self.groq_model)
                    final_response = groq_response
                    
                    # Agregar informaci√≥n de visualizaci√≥n si existe
                    if visualization_info:
                        final_response += f"\n\nüìä **Visualizaciones**: {visualization_info}"
                    
                    logger.info("üß† Respuesta generada con IA avanzada + Groq")
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error en generaci√≥n con Groq, usando respuesta inteligente pura: {e}")
                    final_response = intelligent_response
                    if visualization_info:
                        final_response += f"\n\nüìä **Visualizaciones**: {visualization_info}"
            else:
                # Fallback a generaci√≥n b√°sica
                final_response = "No se pudieron generar insights inteligentes. Verifique la conectividad con los sistemas de datos."
            
            # 4. Registrar uso y agregar informaci√≥n de l√≠mites si es necesario
            estimated_tokens = len(final_response) // 4
            usage_info = usage_tracker.track_request(self.groq_model, estimated_tokens)
            
            # Agregar informaci√≥n de uso si est√° cerca del l√≠mite
            if usage_info["status"] in ["warning", "critical"]:
                remaining_percentage = 100 - usage_info["requests_percentage"]
                usage_footer = f"""

---
üìä **Uso de API**: {usage_info['requests_used']}/{usage_info['requests_limit']} consultas ({remaining_percentage:.1f}% disponible)
"""
            
            state["final_response"] = final_response + usage_footer
            state["execution_status"] = "response_generated"
            state["usage_info"] = usage_info
            state["chart_base64_list"] = chart_paths  # Incluir gr√°ficos base64 en el estado
            
            logger.info(f"   ‚úÖ Respuesta generada con Groq - Uso: {usage_info['requests_used']}/{usage_info['requests_limit']}")
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error en response_generator_node: {e}")
            # Respuesta de fallback
            state["final_response"] = self._generate_fallback_response(state)
            state["execution_status"] = "fallback_response"
            return state
    
    def _generate_basic_intelligent_response(self, user_query: str, formatted_data: str, analysis: Dict) -> str:
        """Genera respuesta b√°sica inteligente cuando los sistemas avanzados no est√°n disponibles."""
        if not formatted_data:
            return "No hay datos disponibles para generar una respuesta."
        
        # Analizar la consulta para personalizar la respuesta
        query_lower = user_query.lower()
        
        # Respuesta base con estructura inteligente
        response = f"""
üß† **AN√ÅLISIS INTELIGENTE IoT**

üìã **Consulta**: {user_query}

üìä **Resumen del Sistema**:
‚Ä¢ Dispositivos activos: {analysis.get('device_analysis', {}).get('total_devices', 0)}
‚Ä¢ Tipos de sensores: {analysis.get('device_analysis', {}).get('total_sensors', 0)}
‚Ä¢ Registros procesados: {analysis.get('total_records', 0)}
‚Ä¢ Tasa de √©xito del procesamiento: {analysis.get('processing_success_rate', 0):.1f}%

üìà **Datos Procesados**:
{formatted_data}
"""
        
        # Agregar insights estad√≠sticos si est√°n disponibles
        if analysis.get('statistical_analysis', {}).get('insights'):
            response += f"""

üí° **Insights Autom√°ticos**:
"""
            for insight in analysis['statistical_analysis']['insights']:
                response += f"‚Ä¢ {insight}\n"
        
        # Agregar alertas si est√°n disponibles
        if analysis.get('intelligent_alerts'):
            response += f"""

üö® **Alertas del Sistema**:
"""
            for alert in analysis['intelligent_alerts']:
                response += f"‚Ä¢ {alert}\n"
        
        # Agregar predicciones si est√°n disponibles
        if analysis.get('predictive_analysis', {}).get('predictions'):
            response += f"""

üîÆ **Predicciones**:
"""
            for prediction in analysis['predictive_analysis']['predictions']:
                response += f"‚Ä¢ {prediction}\n"
        
        response += f"""

‚úÖ **Sistema de Inteligencia**: Activado (modo b√°sico)
‚è∞ **An√°lisis completado**: {datetime.now().strftime('%H:%M:%S')}
"""
        
        return response
    
    async def _data_verification_node(self, state: IoTAgentState) -> IoTAgentState:
        """
        Nodo para verificar la respuesta y detectar alucinaciones.
        
        Args:
            state: Estado actual del agente
            
        Returns:
            Estado actualizado
        """
        try:
            logger.info("üîç Ejecutando data_verification_node (Cloud)")
            
            response = state.get("final_response", "")
            real_sensors = state.get("sensor_summary", {}).get("sensors", [])
            
            # Verificaci√≥n simple de alucinaciones
            verification = {
                "status": "verified",
                "hallucinations_detected": [],
                "confidence": 0.9,
                "timestamp": datetime.now().isoformat()
            }
            
            # Detectar sensores mencionados que no existen en el hardware real
            # SOLO tenemos: temperatura (NTC/thermistores) y LDR (luminosidad)
            problematic_sensors = ["humidity", "humedad", "pressure", "presi√≥n", "co2", "voltage", "voltaje", "motion", "movimiento"]
            for sensor in problematic_sensors:
                if sensor.lower() in response.lower() and sensor not in real_sensors:
                    verification["hallucinations_detected"].append(f"Sensor inexistente mencionado: {sensor} - Solo tenemos temperatura y LDR")
                    verification["confidence"] -= 0.2
            
            # Ajustar status basado en confianza
            if verification["confidence"] < 0.5:
                verification["status"] = "needs_review"
            elif verification["confidence"] < 0.8:
                verification["status"] = "caution"
            
            state["verification_status"] = verification
            state["execution_status"] = "verification_complete"
            
            logger.info(f"   ‚úÖ Verificaci√≥n completada: {verification['status']}")
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error en data_verification_node: {e}")
            state["verification_status"] = {"status": "error", "error": str(e)}
            state["execution_status"] = "verification_error"
            return state
    
    async def process_query(self, user_query: str, thread_id: str = "cloud-session") -> Dict[str, Any]:
        """
        Procesar consulta del usuario usando el agente cloud.
        
        Args:
            user_query: Consulta del usuario
            thread_id: ID del hilo de conversaci√≥n
            
        Returns:
            Dict con la respuesta procesada
        """
        try:
            if not self.is_initialized:
                await self.initialize()
            
            logger.info(f"üîÑ Procesando consulta cloud: {user_query[:100]}...")
            
            # Crear estado inicial
            initial_state = create_initial_state(user_query)
            
            # Ejecutar graph
            config = {"configurable": {"thread_id": thread_id}}
            
            result = await self.graph.ainvoke(initial_state, config=config)
            
            # Formatear respuesta
            response = {
                "success": True,
                "response": result.get("final_response", "No se pudo generar respuesta"),
                "execution_status": result.get("execution_status", "unknown"),
                "verification": result.get("verification_status", {}),
                "chart_base64_list": result.get("chart_base64_list", []),
                "data_summary": {
                    "total_records": len(result.get("raw_data", [])),
                    "sensors": result.get("sensor_summary", {}).get("sensors", []),
                    "devices": result.get("sensor_summary", {}).get("devices", [])
                },
                "timestamp": datetime.now().isoformat(),
                "model_used": self.groq_model
            }
            
            logger.info("‚úÖ Consulta cloud procesada exitosamente")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando consulta cloud: {e}")
            return {
                "success": False,
                "error": str(e),
                "response": "Error procesando la consulta. Por favor intenta nuevamente.",
                "timestamp": datetime.now().isoformat()
            }
    
    def _check_jetson_api_status(self) -> Dict[str, Any]:
        """
        Verificar el estado de la API de Jetson.
        
        Returns:
            Diccionario con el estado de la API
        """
        try:
            # Aqu√≠ ir√≠a la verificaci√≥n real de la API de Jetson
            # Por ejemplo: response = requests.get(f"{JETSON_API_URL}/health", timeout=5)
            
            return {
                "status": "offline",
                "error": "API_JETSON_OFFLINE",
                "message": "La API de la Jetson no est√° disponible",
                "instructions": [
                    "üîß Verificar que la Jetson est√© encendida y conectada a la red",
                    "üì° Confirmar que los servicios systemd est√©n ejecut√°ndose:",
                    "   sudo systemctl status iot-api-service",
                    "   sudo systemctl status sensor-collector-service", 
                    "üåê Verificar conectividad de red desde la Jetson",
                    "üìã Revisar logs del sistema: journalctl -u iot-api-service -f",
                    "üîÑ Reiniciar servicios si es necesario: sudo systemctl restart iot-api-service"
                ]
            }
        except Exception as e:
            return {
                "status": "error",
                "error": "CONNECTION_ERROR", 
                "message": f"Error al verificar API de Jetson: {str(e)}",
                "instructions": [
                    "üö® Error de conexi√≥n con la Jetson",
                    "üîå Verificar cables de red y alimentaci√≥n",
                    "üì° Confirmar IP de la Jetson en la red local",
                    "üîß Revisar configuraci√≥n de firewall en la Jetson"
                ]
            }
    
    def _format_data_for_model(self, data: List[Dict], analysis: Dict, is_direct_query: bool = False, query_info: Dict = None) -> str:
        """
        Formatear datos para el modelo con configuraci√≥n espec√≠fica de dispositivos.
        
        Args:
            data: Datos de sensores
            analysis: An√°lisis de datos
            is_direct_query: Si es una consulta directa que requiere lista de datos
            query_info: Informaci√≥n adicional sobre el tipo de consulta
            
        Returns:
            Datos formateados como string con configuraci√≥n detallada
        """
        if query_info is None:
            query_info = {}
        if is_direct_query:
            # FORMATO DIRECTO - Para consultas espec√≠ficas como "√∫ltimos 10 registros" o "√∫ltimos X minutos"
            
            # T√≠tulo adaptativo seg√∫n el tipo de consulta
            if query_info.get("is_time_query", False):
                time_value = query_info.get("time_value", "X")
                time_unit = query_info.get("time_unit", "tiempo")
                formatted = f"=== REGISTROS DE LOS √öLTIMOS {time_value} {time_unit.upper()} ===\n"
            elif query_info.get("is_count_query", False):
                formatted = f"=== LISTA DE REGISTROS SOLICITADOS ===\n"
            else:
                formatted = f"=== REGISTROS DE SENSORES ===\n"
            
            formatted += f"Total encontrado: {len(data)} registros\n\n"
            
            # Agrupar por dispositivo para mejor legibilidad
            by_device = {}
            for record in data:
                device_id = record.get("device_id", "unknown")
                if device_id not in by_device:
                    by_device[device_id] = []
                by_device[device_id].append(record)
            
            # Siempre mostrar agrupado por dispositivo para consultas de tiempo
            if len(by_device) > 1 or query_info.get("is_time_query", False):
                for device_id, device_records in by_device.items():
                    formatted += f"üì± DISPOSITIVO: {device_id} ({len(device_records)} registros)\n"
                    
                    for i, record in enumerate(device_records[:15], 1):  # M√°ximo 15 por dispositivo
                        sensor_type = record.get("sensor_type", "unknown")
                        value = record.get("value", "N/A")
                        timestamp = record.get("timestamp", "unknown")
                        unit = record.get("unit", "")
                        
                        # Determinar unidad apropiada
                        if not unit:
                            if sensor_type in ['t1', 't2', 'avg', 'temperature_1', 'temperature_2', 'temperature_avg', 'ntc_entrada', 'ntc_salida']:
                                unit = "¬∞C"
                            elif sensor_type == 'ldr':
                                unit = " (unidades de luz)"
                        
                        formatted += f"   {i}. {sensor_type}: {value}{unit} ({timestamp})\n"
                    
                    if len(device_records) > 15:
                        formatted += f"   ... y {len(device_records) - 15} registros m√°s de este dispositivo.\n"
                    formatted += "\n"
            else:
                # Un solo dispositivo, formato simple
                for i, record in enumerate(data[:20], 1):  # M√°ximo 20 para no saturar
                    device_id = record.get("device_id", "unknown")
                    sensor_type = record.get("sensor_type", "unknown")
                    value = record.get("value", "N/A")
                    timestamp = record.get("timestamp", "unknown")
                    unit = record.get("unit", "")
                    
                    # Determinar unidad apropiada
                    if not unit:
                        if sensor_type in ['t1', 't2', 'avg', 'temperature_1', 'temperature_2', 'temperature_avg', 'ntc_entrada', 'ntc_salida']:
                            unit = "¬∞C"
                        elif sensor_type == 'ldr':
                            unit = " (unidades de luz)"
                    
                    formatted += f"{i}. {device_id} - {sensor_type}: {value}{unit} ({timestamp})\n"
                
                if len(data) > 20:
                    formatted += f"\n... y {len(data) - 20} registros m√°s disponibles.\n"
            
            return formatted
        
        else:
            # FORMATO ANAL√çTICO - Para an√°lisis completo
            formatted = f"=== CONFIGURACI√ìN REAL DE DISPOSITIVOS ===\n"
            
            # Configuraci√≥n espec√≠fica para evitar alucinaciones
            formatted += "üîß ARDUINO ETHERNET (arduino_eth_001):\n"
            formatted += "   - IP: 192.168.0.106\n"
            formatted += "   - SENSORES: SOLO t1, t2, avg (temperaturas √∫nicamente)\n"
            formatted += "   - NO TIENE: LDR, sensor de luz, luminosidad\n\n"
            
            formatted += "üì° ESP32 WIFI (esp32_wifi_001):\n"
            formatted += "   - IP: 192.168.0.105\n"
            formatted += "   - SENSORES: ntc_entrada, ntc_salida (temperaturas) + ldr (luz)\n\n"
            
            formatted += f"=== DATOS ACTUALES ===\n"
            formatted += f"Total de registros: {analysis['total_records']}\n"
            formatted += f"Dispositivos activos: {', '.join(analysis['devices'])}\n"
            formatted += f"Sensores disponibles: {', '.join(analysis['sensors'])}\n\n"
            
            # √öltimas lecturas organizadas por dispositivo
            formatted += "√öLTIMAS LECTURAS POR DISPOSITIVO:\n"
            latest_readings = analysis.get("latest_readings", {})
            
            # Agrupar por dispositivo
            by_device = {}
            for sensor, reading in latest_readings.items():
                device = reading['device']
                if device not in by_device:
                    by_device[device] = []
                by_device[device].append((sensor, reading))
            
            for device, sensors in by_device.items():
                formatted += f"\n{device}:\n"
                for sensor, reading in sensors:
                    unit = "¬∞C" if sensor in ['t1', 't2', 'avg', 'ntc_entrada', 'ntc_salida'] else ""
                    formatted += f"   ‚Ä¢ {sensor}: {reading['value']}{unit}\n"
            
            return formatted
    
    def _generate_fallback_response(self, state: IoTAgentState) -> str:
        """
        Generar respuesta de fallback cuando HuggingFace falla.
        
        Args:
            state: Estado actual
            
        Returns:
            Respuesta de fallback
        """
        response = "**Informe de Sensores IoT - Cloud Agent**\n\n"
        
        sensor_summary = state.get("sensor_summary", {})
        total_records = sensor_summary.get("total_records", 0)
        
        if total_records > 0:
            response += f"Se procesaron {total_records} registros de sensores.\n\n"
            
            sensors = sensor_summary.get("sensors", [])
            devices = sensor_summary.get("devices", [])
            
            response += f"**Dispositivos activos**: {', '.join(devices)}\n"
            response += f"**Tipos de sensores**: {', '.join(sensors)}\n\n"
            
            latest_readings = sensor_summary.get("latest_readings", {})
            if latest_readings:
                response += "**√öltimas lecturas**:\n"
                for sensor, reading in latest_readings.items():
                    unit = "¬∞C" if sensor in ['t1', 't2', 'avg', 'ntc_entrada', 'ntc_salida'] else ""
                    response += f"‚Ä¢ {sensor}: {reading['value']}{unit}\n"
        else:
            response += "No hay datos de sensores disponibles en este momento.\n"
        
        response += f"\n**Generado por**: Cloud IoT Agent con Groq\n"
        response += f"**Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        return response
    
    async def health_check(self) -> Dict[str, Any]:
        """
        Verificar estado de salud del agente cloud incluyendo uso de API.
        
        Returns:
            Dict con estado de salud y uso de API
        """
        try:
            health = {
                "agent_status": "healthy" if self.is_initialized else "not_initialized",
                "groq_status": "unknown",
                "jetson_status": "unknown",
                "last_check": datetime.now().isoformat()
            }
            
            if self.is_initialized:
                # Test Groq
                groq_test = self.groq_integration.test_connection()
                health["groq_status"] = "success" if groq_test.get("success") else "fallback"
                
                # Test Jetson (opcional)
                if self.jetson_connector:
                    jetson_test = self.jetson_connector.get_health_status()
                    health["jetson_status"] = jetson_test.get("status", "error")
                else:
                    health["jetson_status"] = "not_configured"
                
                # Agregar informaci√≥n de uso de API
                usage_info = usage_tracker.get_usage_info(self.groq_model)
                health["api_usage"] = {
                    "model": self.groq_model,
                    "model_description": usage_info.get("model_description", "Desconocido"),
                    "requests_used": usage_info.get("requests_used", 0),
                    "requests_limit": usage_info.get("requests_limit", 0),
                    "requests_remaining": usage_info.get("requests_remaining", 0),
                    "tokens_used": usage_info.get("tokens_used", 0),
                    "tokens_limit": usage_info.get("tokens_limit", 0),
                    "tokens_remaining": usage_info.get("tokens_remaining", 0),
                    "usage_percentage": usage_info.get("requests_percentage", 0),
                    "status": usage_info.get("status", "unknown"),
                    "can_make_request": usage_info.get("can_make_request", True),
                    "daily_reset_date": usage_info.get("date", "unknown")
                }
            
            health["overall_status"] = "healthy" if all([
                health["agent_status"] == "healthy",
                health["groq_status"] in ["success", "fallback"]  # Fallback tambi√©n es v√°lido
            ]) else "degraded"
            
            return health
            
        except Exception as e:
            return {
                "overall_status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def process_query_sync(self, user_query: str, thread_id: str = "cloud-session", analysis_hours: float = None) -> str:
        """
        Versi√≥n s√≠ncrona de process_query para usar en Streamlit.
        
        Args:
            user_query: Consulta del usuario
            thread_id: ID del hilo de conversaci√≥n
            analysis_hours: Horas para an√°lisis temporal (None = usar configuraci√≥n por defecto)
            
        Returns:
            String con la respuesta procesada
        """
        import asyncio
        import nest_asyncio
        
        try:
            # Aplicar nest_asyncio para permitir loops anidados
            nest_asyncio.apply()
            
            # Agregar informaci√≥n temporal al contexto si se especifica
            if analysis_hours:
                # Modificar la consulta para incluir contexto temporal
                temporal_context = f"\n[CONFIGURACI√ìN TEMPORAL: Analizar datos de las √∫ltimas {analysis_hours} horas]"
                enhanced_query = user_query + temporal_context
            else:
                enhanced_query = user_query
            
            # Ejecutar la funci√≥n async
            result = asyncio.run(self.process_query(enhanced_query, thread_id))
            
            # Extraer respuesta del resultado
            if isinstance(result, dict):
                return result.get('response', str(result))
            else:
                return str(result)
                
        except Exception as e:
            logger.error(f"‚ùå Error en process_query_sync: {e}")
            # FALLBACK DIRECTO cuando el agente async falla
            return self.process_query_direct_fallback(user_query)
    
    def process_query_direct_fallback(self, user_query: str) -> str:
        """
        Fallback DIRECTO que usa la misma l√≥gica exitosa del frontend.
        Se ejecuta cuando el agente principal falla.
        
        Args:
            user_query: Consulta del usuario
            
        Returns:
            Respuesta usando datos directos (misma l√≥gica del frontend)
        """
        try:
            logger.info(f"üöÄ FALLBACK DIRECTO para consulta: {user_query}")
            
            # Usar DirectAPIAgent (misma l√≥gica del frontend exitoso)
            if hasattr(self, 'direct_api_agent') and self.direct_api_agent:
                # Obtener datos formateados para an√°lisis
                formatted_data = self.direct_api_agent.format_for_analysis(user_query)
                
                # Si tenemos datos, procesarlos
                if "üìä ESTADO ACTUAL DEL SISTEMA IoT" in formatted_data:
                    logger.info("‚úÖ Datos obtenidos exitosamente con fallback directo")
                    
                    # Crear respuesta contextual b√°sica
                    if any(keyword in user_query.lower() for keyword in ['gr√°fico', 'grafica', 'visualiza', 'chart', 'plot']):
                        response = f"""üìä **Estado Actual del Sistema**

{formatted_data}

üìà **Visualizaci√≥n Solicitada**: Para generar gr√°ficos, utiliza la funcionalidad de gr√°ficos en la interfaz. Los datos est√°n disponibles y actualizados.

üí° **Datos Disponibles**: El sistema est√° funcionando correctamente con dispositivos activos reportando datos en tiempo real."""
                    
                    elif any(keyword in user_query.lower() for keyword in ['temperatura', 'sensor', 'dispositivo']):
                        response = f"""üå°Ô∏è **An√°lisis de Sensores**

{formatted_data}

üîç **An√°lisis**: Los sensores est√°n funcionando correctamente y reportando datos actualizados. 

üì± **Estado de Dispositivos**: Todos los dispositivos est√°n activos y transmitiendo datos en tiempo real."""
                    
                    else:
                        response = f"""üìã **Respuesta del Sistema IoT**

{formatted_data}

‚úÖ **Sistema Operativo**: Todos los componentes est√°n funcionando correctamente.

üí¨ **Consulta**: "{user_query}" - El sistema est√° listo para procesar tu solicitud con los datos mostrados arriba."""
                    
                    return response
                else:
                    logger.warning("‚ö†Ô∏è Fallback directo obtuvo datos pero con formato inesperado")
                    return f"‚ö†Ô∏è {formatted_data}"
            else:
                logger.error("‚ùå Direct API Agent no disponible para fallback")
                return "‚ùå Error: Sistema de fallback directo no disponible. Revisa la configuraci√≥n de la API."
                
        except Exception as e:
            logger.error(f"‚ùå Error en fallback directo: {e}")
            return f"‚ùå Error en sistema de fallback: {str(e)}. Verifica la conectividad con la API."
            logger.error(f"Error en process_query_sync: {e}")
            return f"‚ùå Error procesando consulta: {str(e)}"

    # üîß M√âTODOS AUXILIARES PARA FALLBACK (CUANDO SISTEMAS DE INTELIGENCIA NO EST√ÅN DISPONIBLES)
    
    def _generate_fallback_error_message(self, state: IoTAgentState) -> str:
        """Genera mensaje de error cuando no hay datos disponibles."""
        if "error" in state:
            error_info = state["error"]
            return f"""
üö® ERROR: No se pudieron obtener datos de sensores

{error_info.get('message', 'Error desconocido')}

üìã INSTRUCCIONES PARA RESOLVER:
""" + "\n".join(error_info.get('instructions', []))
        else:
            return """
üö® ERROR: No hay datos de sensores disponibles

La API de la Jetson no est√° respondiendo. Por favor:

üîß Verificar que la Jetson est√© encendida y conectada a la red
üì° Confirmar que los servicios systemd est√©n ejecut√°ndose:
   sudo systemctl status iot-api-service
   sudo systemctl status sensor-collector-service
üåê Verificar conectividad de red desde la Jetson
üìã Revisar logs del sistema: journalctl -u iot-api-service -f
üîÑ Reiniciar servicios si es necesario: sudo systemctl restart iot-api-service
"""
    
    def _generate_data_format_error(self, raw_data: List) -> str:
        """Genera mensaje de error de formato de datos."""
        return f"""
üö® ERROR: Los datos obtenidos tienen formato incorrecto

Los datos de la API est√°n llegando pero no tienen el formato esperado.

üìã DATOS RECIBIDOS:
{str(raw_data[:3])}

üîß POSIBLES SOLUCIONES:
üì° Verificar formato de respuesta de la API Jetson
üîÑ Reiniciar servicios de la API: sudo systemctl restart iot-api-service
üåê Verificar que la API retorne JSON v√°lido
"""
    
    def _basic_data_sanitization(self, raw_data: List) -> List[Dict]:
        """Sanitizaci√≥n b√°sica de datos cuando SmartAnalyzer no est√° disponible."""
        processed_data = []
        for item in raw_data:
            try:
                if isinstance(item, dict):
                    if all(key in item for key in ['device_id', 'sensor_type', 'value']):
                        processed_data.append(item)
                elif isinstance(item, str):
                    import json
                    try:
                        parsed_item = json.loads(item)
                        if isinstance(parsed_item, dict) and all(key in parsed_item for key in ['device_id', 'sensor_type', 'value']):
                            processed_data.append(parsed_item)
                    except json.JSONDecodeError:
                        pass
            except Exception:
                pass
        return processed_data
    
    def _basic_query_analysis(self, user_query: str) -> Dict:
        """An√°lisis b√°sico de consulta cuando AutomaticInsightsEngine no est√° disponible."""
        import re
        query_lower = user_query.lower()
        
        # Detectar tipos b√°sicos de consulta
        intent = "general_query"
        if any(word in query_lower for word in ["√∫ltimos", "listar", "mostrar", "dame"]):
            intent = "data_request"
        elif any(word in query_lower for word in ["analiza", "tendencia", "comportamiento"]):
            intent = "analysis_request"
        
        # Detectar n√∫meros y tiempo
        numbers = re.findall(r'\d+', user_query)
        time_keywords = ["minuto", "minutos", "hora", "horas"]
        has_time_reference = any(keyword in query_lower for keyword in time_keywords)
        
        return {
            "intent": intent,
            "numbers_found": numbers,
            "has_time_reference": has_time_reference,
            "confidence": 0.5  # Baja confianza para an√°lisis b√°sico
        }
    
    def _basic_device_analysis(self, processed_data: List[Dict]) -> Dict:
        """An√°lisis b√°sico de dispositivos cuando DynamicSensorDetector no est√° disponible."""
        devices = set()
        sensors = set()
        
        for record in processed_data:
            if isinstance(record, dict):
                devices.add(record.get("device_id", "unknown"))
                sensors.add(record.get("sensor_type", "unknown"))
        
        return {
            "total_devices": len(devices),
            "total_sensors": len(sensors),
            "devices": list(devices),
            "sensors": list(sensors),
            "analysis_type": "basic"
        }
    
    def _basic_statistical_analysis(self, processed_data: List[Dict]) -> Dict:
        """An√°lisis estad√≠stico b√°sico cuando SmartAnalyzer no est√° disponible."""
        if not processed_data:
            return {"insights": [], "statistics": {}}
        
        # Estad√≠sticas b√°sicas
        total_records = len(processed_data)
        
        # Contar valores por sensor
        sensor_stats = {}
        for record in processed_data:
            if isinstance(record, dict):
                sensor_type = record.get("sensor_type", "unknown")
                value = record.get("value")
                
                if sensor_type not in sensor_stats:
                    sensor_stats[sensor_type] = []
                
                try:
                    numeric_value = float(value)
                    sensor_stats[sensor_type].append(numeric_value)
                except (ValueError, TypeError):
                    pass
        
        insights = [f"Total de {total_records} registros procesados"]
        
        for sensor, values in sensor_stats.items():
            if values:
                avg_val = sum(values) / len(values)
                insights.append(f"{sensor}: {len(values)} lecturas, promedio {avg_val:.2f}")
        
        return {
            "insights": insights,
            "statistics": sensor_stats,
            "analysis_type": "basic"
        }
    
    def _basic_data_formatting(self, processed_data: List[Dict], analysis: Dict) -> str:
        """Formateo b√°sico de datos cuando AdvancedReportGenerator no est√° disponible."""
        if not processed_data:
            return "No hay datos disponibles para mostrar."
        
        # Crear reporte b√°sico
        report = f"""
üìä RESUMEN DE DATOS IoT

üîç Total de registros: {len(processed_data)}
üì± Dispositivos detectados: {analysis.get('device_analysis', {}).get('total_devices', 0)}
üå°Ô∏è Tipos de sensores: {analysis.get('device_analysis', {}).get('total_sensors', 0)}

üìã √öLTIMOS REGISTROS:
"""
        
        # Mostrar hasta 10 registros recientes
        for i, record in enumerate(processed_data[:10]):
            if isinstance(record, dict):
                device = record.get("device_id", "N/A")
                sensor = record.get("sensor_type", "N/A")
                value = record.get("value", "N/A")
                timestamp = record.get("timestamp", "N/A")
                
                report += f"""
{i+1}. üì± {device} | üå°Ô∏è {sensor}: {value} | ‚è∞ {timestamp}"""
        
        # Agregar insights b√°sicos si est√°n disponibles
        if analysis.get('statistical_analysis', {}).get('insights'):
            report += f"""

üí° INSIGHTS B√ÅSICOS:
"""
            for insight in analysis['statistical_analysis']['insights']:
                report += f"‚Ä¢ {insight}\n"
        
        return report


# Funci√≥n de utilidad para crear instancia cloud
def create_cloud_iot_agent(groq_model: str = "llama-3.1-8b-instant") -> CloudIoTAgent:
    """
    Crear instancia de Cloud IoT Agent.
    
    Args:
        groq_model: Modelo de Groq a usar (gratuito)
        
    Returns:
        Instancia de CloudIoTAgent
    """
    return CloudIoTAgent(groq_model=groq_model)


if __name__ == "__main__":
    # Prueba del Cloud IoT Agent
    import asyncio
    
    async def test_cloud_agent():
        print("üß™ PRUEBA DE CLOUD IOT AGENT")
        print("=" * 50)
        
        try:
            # Crear agente cloud
            agent = create_cloud_iot_agent()
            
            # Health check
            print("1Ô∏è‚É£ Health check...")
            health = await agent.health_check()
            print(f"   Status: {health.get('overall_status')}")
            
            # Procesar consulta de prueba
            print("\n2Ô∏è‚É£ Procesando consulta de prueba...")
            response = await agent.process_query("¬øCu√°l es la temperatura actual?")
            
            print(f"   Success: {response.get('success')}")
            print(f"   Response: {response.get('response', '')[:200]}...")
            print(f"   Model: {response.get('model_used')}")
            
            print("\n‚úÖ Prueba cloud completada")
            
        except Exception as e:
            print(f"‚ùå Error en prueba cloud: {e}")
            print("üí° Configura GROQ_API_KEY para usar Groq API completa (opcional)")
            print("üí° Sin API key, el agente funciona en modo fallback")
    
    asyncio.run(test_cloud_agent())
