"""
üìä M√≥dulo de Visualizaci√≥n Inteligente para IoT
===============================================

Sistema de gr√°ficos que solo se activa cuando:
1. El usuario lo solicita EXPL√çCITAMENTE
2. Es NECESARIO para an√°lisis complejos

NO se usa para consultas simples como "listame X registros"
"""

# Configurar matplotlib para entornos sin display (Streamlit Cloud)
import matplotlib
matplotlib.use('Agg')  # Backend sin display para cloud deployment

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import io
import base64
import logging
import os
import tempfile

import warnings
warnings.filterwarnings('ignore')

# Configurar logging
logger = logging.getLogger(__name__)

# Configurar scikit-learn con manejo de errores para cloud
try:
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("‚ö†Ô∏è scikit-learn no disponible - predicciones ML deshabilitadas")

class IoTVisualizationEngine:
    """
    Motor de visualizaci√≥n inteligente para datos IoT.
    Solo genera gr√°ficos cuando es expl√≠citamente solicitado o necesario.
    """
    
    def __init__(self):
        """Inicializar el motor de visualizaci√≥n"""
        self.supported_chart_types = [
            'time_series', 'statistics', 'comparison', 'prediction', 
            'distribution', 'correlation', 'anomaly_detection'
        ]
        
        # Configurar directorio para gr√°ficos (compatible con Streamlit Cloud)
        self.charts_dir = self._setup_charts_directory()
        
        # Configurar estilo de gr√°ficos
        plt.style.use('default')
        plt.rcParams['figure.figsize'] = (12, 8)
        plt.rcParams['font.size'] = 10
        plt.rcParams['axes.grid'] = True
        plt.rcParams['grid.alpha'] = 0.3
    
    def _setup_charts_directory(self) -> str:
        """
        Configurar directorio para gr√°ficos compatible con Streamlit Cloud.
        Usa directorio temporal si no se puede escribir en charts/.
        """
        try:
            # Intentar usar directorio charts/ local
            charts_dir = os.path.join(os.getcwd(), "charts")
            if not os.path.exists(charts_dir):
                os.makedirs(charts_dir, exist_ok=True)
                
            # Probar escribir un archivo de prueba
            test_file = os.path.join(charts_dir, "test.tmp")
            with open(test_file, 'w') as f:
                f.write("test")
            os.remove(test_file)
            
            logger.info(f"üìä Directorio de gr√°ficos: {charts_dir}")
            return charts_dir
            
        except (PermissionError, OSError) as e:
            # Usar directorio temporal en cloud
            charts_dir = tempfile.mkdtemp(prefix="iot_charts_")
            logger.info(f"üìä Directorio temporal para gr√°ficos: {charts_dir}")
            return charts_dir
    
    def should_generate_charts(self, user_query: str, analysis_type: str = "simple") -> bool:
        """
        Determinar si se deben generar gr√°ficos basado en la consulta del usuario.
        
        Args:
            user_query: Consulta del usuario
            analysis_type: Tipo de an√°lisis (simple, advanced, prediction)
            
        Returns:
            True si se deben generar gr√°ficos, False caso contrario
        """
        query_lower = user_query.lower()
        
        # PALABRAS CLAVE EXPL√çCITAS para gr√°ficos
        explicit_chart_keywords = [
            'gr√°fico', 'grafico', 'gr√°fica', 'grafica', 'graficar', 
            'visualizar', 'visualizaci√≥n', 'visualizacion',
            'chart', 'plot', 'mostrar gr√°fico', 'mostrar grafico',
            'con gr√°fico', 'con grafico', 'graficamente', 'gr√°ficamente'
        ]
        
        # PALABRAS CLAVE que implican an√°lisis avanzado (requieren gr√°ficos)
        advanced_analysis_keywords = [
            'estad√≠sticas avanzadas', 'an√°lisis completo', 'an√°lisis avanzado',
            'tendencias', 'predicci√≥n', 'pron√≥stico', 'comportamiento temporal',
            'evoluci√≥n', 'patr√≥n', 'patrones', 'correlaci√≥n', 'distribuci√≥n',
            'anomal√≠as', 'estad√≠stica descriptiva completa'
        ]
        
        # NO graficar para consultas simples
        simple_query_keywords = [
            'listame', 'muestra', 'dame', 'cu√°les son', 'qu√© datos',
            '√∫ltimos registros', 'registros de'
        ]
        
        # 1. Si solicita EXPL√çCITAMENTE gr√°ficos
        if any(keyword in query_lower for keyword in explicit_chart_keywords):
            logger.info("üé® Gr√°ficos solicitados EXPL√çCITAMENTE")
            return True
        
        # 2. Si es an√°lisis avanzado (requiere gr√°ficos por necesidad)
        if any(keyword in query_lower for keyword in advanced_analysis_keywords):
            logger.info("üìä Gr√°ficos NECESARIOS para an√°lisis avanzado")
            return True
        
        # 3. Si es consulta simple, NO graficar
        if any(keyword in query_lower for keyword in simple_query_keywords):
            logger.info("üìã Consulta simple - SIN gr√°ficos")
            return False
        
        # 4. Para tipos de an√°lisis espec√≠ficos
        if analysis_type in ['prediction', 'advanced_statistics', 'trend_analysis']:
            logger.info(f"üìà Gr√°ficos necesarios para {analysis_type}")
            return True
        
        # Por defecto, NO generar gr√°ficos
        logger.info("üö´ No se requieren gr√°ficos")
        return False
    
    def generate_time_series_chart(self, data: List[Dict], title: str = "Serie Temporal") -> Optional[str]:
        """
        Generar gr√°fico de serie temporal para datos IoT.
        
        Args:
            data: Lista de registros con timestamp, device_id, sensor_type, value
            title: T√≠tulo del gr√°fico
            
        Returns:
            String base64 del gr√°fico o None si hay error
        """
        try:
            if not data:
                return None
            
            df = pd.DataFrame(data)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp')
            
            fig, ax = plt.subplots(figsize=(14, 8))
            
            # Agrupar por dispositivo y tipo de sensor
            for device_id in df['device_id'].unique():
                device_data = df[df['device_id'] == device_id]
                
                for sensor_type in device_data['sensor_type'].unique():
                    sensor_data = device_data[device_data['sensor_type'] == sensor_type]
                    
                    if len(sensor_data) > 0:
                        label = f"{device_id} - {sensor_type}"
                        ax.plot(sensor_data['timestamp'], sensor_data['value'], 
                               marker='o', markersize=4, linewidth=2, label=label, alpha=0.8)
            
            ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
            ax.set_xlabel('Tiempo', fontsize=12)
            ax.set_ylabel('Valor del Sensor', fontsize=12)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)
            
            # Formato de fechas en eje X
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))
            ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=30))
            plt.xticks(rotation=45)
            
            plt.tight_layout()
            
            # Convertir a base64 para mostrar directamente en Streamlit
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
            buffer.seek(0)
            chart_base64 = base64.b64encode(buffer.getvalue()).decode()
            plt.close()
            
            logger.info(f"‚úÖ Gr√°fico de serie temporal generado (base64)")
            return chart_base64
            
        except Exception as e:
            logger.error(f"Error generando gr√°fico de serie temporal: {e}")
            return None
    
    def generate_statistics_chart(self, data: List[Dict], title: str = "Estad√≠sticas por Sensor") -> Optional[str]:
        """
        Generar gr√°fico de estad√≠sticas (barras con estad√≠sticas descriptivas).
        """
        try:
            if not data:
                return None
            
            df = pd.DataFrame(data)
            
            # Calcular estad√≠sticas por sensor y dispositivo
            stats = df.groupby(['device_id', 'sensor_type'])['value'].agg([
                'count', 'mean', 'std', 'min', 'max'
            ]).reset_index()
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
            
            # Gr√°fico 1: Promedio por sensor
            sensor_groups = stats.groupby('sensor_type')['mean'].mean().sort_values(ascending=False)
            ax1.bar(range(len(sensor_groups)), sensor_groups.values, color='skyblue', alpha=0.8)
            ax1.set_title('Valor Promedio por Tipo de Sensor', fontweight='bold')
            ax1.set_xticks(range(len(sensor_groups)))
            ax1.set_xticklabels(sensor_groups.index, rotation=45)
            ax1.set_ylabel('Valor Promedio')
            
            # Gr√°fico 2: Cantidad de registros por dispositivo
            device_counts = df['device_id'].value_counts()
            ax2.pie(device_counts.values, labels=device_counts.index, autopct='%1.1f%%', 
                   colors=['lightcoral', 'lightblue', 'lightgreen', 'lightyellow'])
            ax2.set_title('Distribuci√≥n de Registros por Dispositivo', fontweight='bold')
            
            # Gr√°fico 3: Rango de valores (min-max) por sensor
            x_pos = range(len(stats))
            ax3.errorbar(x_pos, stats['mean'], 
                        yerr=[stats['mean'] - stats['min'], stats['max'] - stats['mean']], 
                        fmt='o', capsize=5, capthick=2, alpha=0.8)
            ax3.set_title('Rango de Valores por Sensor', fontweight='bold')
            ax3.set_xticks(x_pos)
            ax3.set_xticklabels([f"{row['device_id']}\n{row['sensor_type']}" 
                               for _, row in stats.iterrows()], rotation=45)
            ax3.set_ylabel('Valor')
            
            # Gr√°fico 4: Desviaci√≥n est√°ndar
            ax4.bar(x_pos, stats['std'], color='orange', alpha=0.7)
            ax4.set_title('Desviaci√≥n Est√°ndar por Sensor', fontweight='bold')
            ax4.set_xticks(x_pos)
            ax4.set_xticklabels([f"{row['device_id']}\n{row['sensor_type']}" 
                               for _, row in stats.iterrows()], rotation=45)
            ax4.set_ylabel('Desviaci√≥n Est√°ndar')
            
            plt.suptitle(title, fontsize=16, fontweight='bold', y=0.98)
            plt.tight_layout()
            
            # Convertir a base64 para mostrar directamente en Streamlit
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
            buffer.seek(0)
            chart_base64 = base64.b64encode(buffer.getvalue()).decode()
            plt.close()
            
            logger.info(f"‚úÖ Gr√°fico de estad√≠sticas generado (base64)")
            return chart_base64
            
        except Exception as e:
            logger.error(f"Error generando gr√°fico de estad√≠sticas: {e}")
            return None
    
    def generate_prediction_chart(self, data: List[Dict], hours_ahead: int = 24, 
                                title: str = "Predicci√≥n de Sensores") -> Optional[str]:
        """
        Generar gr√°fico de predicci√≥n usando regresi√≥n polinomial simple.
        Requiere scikit-learn.
        """
        try:
            if not SKLEARN_AVAILABLE:
                logger.warning("üìä Predicciones no disponibles - scikit-learn no instalado")
                return None
                
            if not data or len(data) < 10:
                return None
            
            df = pd.DataFrame(data)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp')
            
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            axes = axes.flatten()
            
            plot_count = 0
            max_plots = 4
            
            for device_id in df['device_id'].unique():
                if plot_count >= max_plots:
                    break
                    
                device_data = df[df['device_id'] == device_id]
                
                for sensor_type in device_data['sensor_type'].unique():
                    if plot_count >= max_plots:
                        break
                    
                    sensor_data = device_data[device_data['sensor_type'] == sensor_type]
                    
                    if len(sensor_data) < 5:
                        continue
                    
                    # Preparar datos para predicci√≥n
                    sensor_data = sensor_data.copy()
                    sensor_data['time_numeric'] = (sensor_data['timestamp'] - sensor_data['timestamp'].min()).dt.total_seconds() / 3600
                    
                    X = sensor_data['time_numeric'].values.reshape(-1, 1)
                    y = sensor_data['value'].values
                    
                    # Crear modelo polinomial simple
                    poly_features = PolynomialFeatures(degree=2)
                    X_poly = poly_features.fit_transform(X)
                    
                    model = LinearRegression()
                    model.fit(X_poly, y)
                    
                    # Generar predicci√≥n
                    last_time = sensor_data['time_numeric'].max()
                    future_times = np.linspace(last_time, last_time + hours_ahead, 50)
                    future_X_poly = poly_features.transform(future_times.reshape(-1, 1))
                    future_predictions = model.predict(future_X_poly)
                    
                    # Crear timestamps futuros
                    future_timestamps = [sensor_data['timestamp'].max() + timedelta(hours=h) 
                                       for h in (future_times - last_time)]
                    
                    ax = axes[plot_count]
                    
                    # Plotear datos hist√≥ricos
                    ax.plot(sensor_data['timestamp'], sensor_data['value'], 
                           'o-', label='Datos Hist√≥ricos', linewidth=2, markersize=4)
                    
                    # Plotear predicci√≥n
                    ax.plot(future_timestamps, future_predictions, 
                           '--', label=f'Predicci√≥n {hours_ahead}h', linewidth=2, alpha=0.8, color='red')
                    
                    ax.set_title(f'{device_id} - {sensor_type}', fontweight='bold')
                    ax.set_xlabel('Tiempo')
                    ax.set_ylabel('Valor')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    
                    # Formato de fechas
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))
                    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
                    
                    plot_count += 1
            
            # Ocultar subplots no utilizados
            for i in range(plot_count, max_plots):
                axes[i].set_visible(False)
            
            plt.suptitle(title, fontsize=16, fontweight='bold', y=0.98)
            plt.tight_layout()
            
            # Convertir a base64 para mostrar directamente en Streamlit
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')
            buffer.seek(0)
            chart_base64 = base64.b64encode(buffer.getvalue()).decode()
            plt.close()
            
            logger.info(f"üìä Gr√°fico de predicci√≥n generado (base64)")
            return chart_base64
            
        except Exception as e:
            logger.error(f"Error generando gr√°fico de predicci√≥n: {e}")
            return None
    
    def generate_comprehensive_analysis(self, data: List[Dict], analysis_hours: int = 24) -> Dict[str, Any]:
        """
        Generar an√°lisis completo con m√∫ltiples gr√°ficos cuando es necesario.
        
        Args:
            data: Datos de sensores
            analysis_hours: Horas de an√°lisis
            
        Returns:
            Dict con gr√°ficos y estad√≠sticas
        """
        try:
            results = {
                'charts': {},
                'statistics': {},
                'insights': []
            }
            
            if not data:
                return results
            
            # 1. Gr√°fico de serie temporal
            time_series_chart = self.generate_time_series_chart(
                data, f"Serie Temporal - √öltimas {analysis_hours} Horas"
            )
            if time_series_chart:
                results['charts']['time_series'] = time_series_chart
            
            # 2. Gr√°fico de estad√≠sticas
            stats_chart = self.generate_statistics_chart(
                data, f"Estad√≠sticas Descriptivas - {analysis_hours}h"
            )
            if stats_chart:
                results['charts']['statistics'] = stats_chart
            
            # 3. Gr√°fico de predicci√≥n
            prediction_chart = self.generate_prediction_chart(
                data, hours_ahead=24, title="Predicci√≥n para las Pr√≥ximas 24 Horas"
            )
            if prediction_chart:
                results['charts']['prediction'] = prediction_chart
            
            # 4. Calcular estad√≠sticas num√©ricas
            df = pd.DataFrame(data)
            
            # Estad√≠sticas por sensor
            sensor_stats = {}
            for device_id in df['device_id'].unique():
                device_data = df[df['device_id'] == device_id]
                sensor_stats[device_id] = {}
                
                for sensor_type in device_data['sensor_type'].unique():
                    sensor_data = device_data[device_data['sensor_type'] == sensor_type]
                    
                    sensor_stats[device_id][sensor_type] = {
                        'count': len(sensor_data),
                        'mean': float(sensor_data['value'].mean()),
                        'std': float(sensor_data['value'].std()),
                        'min': float(sensor_data['value'].min()),
                        'max': float(sensor_data['value'].max()),
                        'range': float(sensor_data['value'].max() - sensor_data['value'].min())
                    }
            
            results['statistics'] = sensor_stats
            
            # 5. Generar insights autom√°ticos
            insights = []
            
            # Insight sobre cantidad de datos
            total_records = len(df)
            devices_count = df['device_id'].nunique()
            sensors_count = df['sensor_type'].nunique()
            
            insights.append(f"üìä Se analizaron {total_records} registros de {devices_count} dispositivos y {sensors_count} tipos de sensores")
            
            # Insight sobre dispositivo m√°s activo
            most_active_device = df['device_id'].value_counts().index[0]
            most_active_count = df['device_id'].value_counts().iloc[0]
            insights.append(f"üì± Dispositivo m√°s activo: {most_active_device} con {most_active_count} registros")
            
            # Insight sobre rangos de temperatura
            temp_sensors = ['temperature_1', 'temperature_2', 'temperature_avg', 'ntc_entrada', 'ntc_salida']
            temp_data = df[df['sensor_type'].isin(temp_sensors)]
            if not temp_data.empty:
                temp_mean = temp_data['value'].mean()
                temp_std = temp_data['value'].std()
                insights.append(f"üå°Ô∏è Temperatura promedio: {temp_mean:.1f}¬∞C (¬±{temp_std:.1f}¬∞C)")
            
            results['insights'] = insights
            
            return results
            
        except Exception as e:
            logger.error(f"Error en an√°lisis completo: {e}")
            return {'charts': {}, 'statistics': {}, 'insights': []}
    
    def generate_charts(self, data: str, user_query: str = "") -> List[str]:
        """
        M√©todo principal para generar gr√°ficos desde el agente.
        
        Args:
            data: Datos formateados como string JSON o lista
            user_query: Consulta del usuario para contexto
            
        Returns:
            Lista de rutas de archivos de gr√°ficos generados
        """
        try:
            # Convertir datos de string a lista si es necesario
            if isinstance(data, str):
                import json
                try:
                    # Intentar parsear como JSON
                    data_list = json.loads(data) if data.strip().startswith('[') else []
                except json.JSONDecodeError:
                    logger.warning("No se pudo parsear los datos como JSON")
                    return []
            else:
                data_list = data
            
            if not data_list:
                logger.warning("No hay datos v√°lidos para generar gr√°ficos")
                return []
            
            logger.info(f"üìä Generando gr√°ficos para {len(data_list)} registros")
            
            # Generar an√°lisis completo
            analysis = self.generate_comprehensive_analysis(data_list)
            
            # Extraer rutas de gr√°ficos del resultado
            charts_dict = analysis.get("charts", {})
            chart_paths = []
            
            for chart_type, path in charts_dict.items():
                if path and isinstance(path, str):
                    chart_paths.append(path)
            
            logger.info(f"‚úÖ Generados {len(chart_paths)} gr√°ficos exitosamente")
            return chart_paths
            
        except Exception as e:
            logger.error(f"Error generando gr√°ficos: {e}")
            return []


def create_visualization_engine() -> IoTVisualizationEngine:
    """Crear instancia del motor de visualizaci√≥n"""
    return IoTVisualizationEngine()

# Alias para compatibilidad
VisualizationEngine = IoTVisualizationEngine